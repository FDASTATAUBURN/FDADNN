theta_boot_2 = (d1%*%epsilon2)[-(1:(nj1*nj3))]
rho_boot = (d2%*%epsilon3)
beta_boot_1=matrix(kro1%*%theta_boot_1,ns,nt)
beta_boot_2=matrix(kro2%*%theta_boot_2,ns,nt)
gamma_boot =z.bs%*%rho_boot
theta_boot_2 = (d1%*%epsilon2)[-(1:(nj1*nj1))]
rho_boot = (d2%*%epsilon3)
beta_boot_1=matrix(kro1%*%theta_boot_1,ns,nt)
beta_boot_2=matrix(kro2%*%theta_boot_2,ns,nt)
gamma_boot =yz.bs%*%rho_boot
max(abs(beta_boot_1))
HAT_z = Z.train2%*%ginv(crossprod(Z.train2,Z.train2))%*%t(Z.train2)
II_z = diag(1, dim(HAT_z)[1], dim(HAT_z)[2])
tao1=matrix(rnorm(500*N, 0, 1), N, 500)
tao2=matrix(rnorm(500*N, 0, 1), N, 500)
tao3=matrix(rnorm(500*N, 0, 1), N, 500)
tao_1=tao_2=tao_3=matrix(NA, N*ns, 500)
for(d in 1:500){
tao_1[,d]=rep(tao1[,d],each=ns)
tao_2[,d]=rep(tao2[,d],each=ns)
tao_3[,d]=rep(tao3[,d],each=ns)
}
Boot_1 = rep(0, 500)
Boot_2 = rep(0, 500)
Boot_3 = rep(0, 500)
res=Z.train1%*%theta+Z.train2%*%rho-Y.train
d1=ginv(t(Z.train1)%*%(II_z - HAT_z)%*%Z.train1)%*%t(Z.train1)
d2=ginv(t(Z.train2)%*%(II - HAT)%*%Z.train2)%*%t(Z.train2)
kro1=kronecker(x1.bs,y1.bs)
kro2=kronecker(x2.bs,y2.bs)
tao.ind = 1:dim(res)[1]
for(www in 1:500){
epsilon1 = res*(tao_1[tao.ind,www])
epsilon2 = res*(tao_2[tao.ind,www])
epsilon3 = res*(tao_3[tao.ind,www])
theta_boot_1 = (d1%*%epsilon1)[(1:(nj1*nj1))]
theta_boot_2 = (d1%*%epsilon2)[-(1:(nj1*nj1))]
rho_boot = (d2%*%epsilon3)
beta_boot_1=matrix(kro1%*%theta_boot_1,ns,nt)
beta_boot_2=matrix(kro2%*%theta_boot_2,ns,nt)
gamma_boot =yz.bs%*%rho_boot
Boot_1[www] = max(abs(beta_boot_1))
Boot_2[www] = max(abs(beta_boot_2))
Boot_3[www] = max(abs(gamma_boot))
}
###########################################
#####  95%   ##############################
alpha = 0.05
Q1 = sort(Boot_1)
Q2 = sort(Boot_2)
e_cdf_1 = 1:length(Q1) / length(Q1)
e_cdf_2 = 1:length(Q2) / length(Q2)
Band1 = Q1[which(e_cdf_1 >= (1-alpha))[1]]
Band2 = Q2[which(e_cdf_2 >= (1-alpha))[1]]
write.csv(Upper_B1, file = "SCB_Upper_Bike_beta1_95.csv")  #ns*nt
write.csv(Lower_B1, file = "SCB_Lower_Bike_beta1_95.csv")  #ns*nt
write.csv(Upper_B2, file = "SCB_Upper_Bike_beta2_95.csv")  #ns*nt
write.csv(Lower_B2, file = "SCB_Lower_Bike_beta2_95.csv")  #ns*nt
write.csv(Upper_Gamma, file = "SCB_Upper_Bike_gamma_95.csv")  #ns*nt
write.csv(Lower_Gamma, file = "SCB_Lower_Bike_gamma_95.csv")  #ns*nt
###Plot###
###Beta###
#persp(t.x, t.y, t(Upper_B1))
###Gamma###
plot(1:24,gamma.hat, type = "l", xlim = c(1, 24), xlab = "Hour", ylab = "", las = 1)
lines(1:24, Upper_Gamma, col = "red", lty = 2)
lines(1:24, Lower_Gamma, col = "red", lty = 2)
abline(h=0, col = "grey")
###Coverage###
S1 = 0
s1 = 0
for(i in 1:24){
for(j in 1:24){
if((Lower_B1[i, j]<=0)&(Upper_B1[i, j]>=0))
S1 = S1+1
else{
s1 = s1+1
}
}
}
S1
s1
S2 = 0
s2 = 0
for(i in 1:24){
for(j in 1:24){
if((Lower_B2[i, j]<=0)&(Upper_B2[i, j]>=0))
S2 = S2+1
else{
s2 = s2+1
}
}
}
S2
s2
alpha = 0.05
Q1 = sort(Boot_1)
Q2 = sort(Boot_2)
Q3 = sort(Boot_3)
e_cdf_1 = 1:length(Q1) / length(Q1)
e_cdf_2 = 1:length(Q2) / length(Q2)
e_cdf_3 = 1:length(Q3) / length(Q3)
Band1 = Q1[which(e_cdf_1 >= (1-alpha))[1]]
Band2 = Q2[which(e_cdf_2 >= (1-alpha))[1]]
Band3 = Q3[which(e_cdf_3 >= (1-alpha))[1]]
Band1
beta1.hat
Upper_B1 = beta1.hat+Band1
Lower_B1 = beta1.hat-Band1
Upper_B2 = beta2.hat+Band2
Lower_B2 = beta2.hat-Band2
Upper_Gamma = gamma.hat+Band3
Lower_Gamma = gamma.hat-Band3
write.csv(Upper_B1, file = "SCB_Upper_Bike_beta1_95.csv")  #ns*nt
write.csv(Lower_B1, file = "SCB_Lower_Bike_beta1_95.csv")  #ns*nt
write.csv(Upper_B2, file = "SCB_Upper_Bike_beta2_95.csv")  #ns*nt
write.csv(Lower_B2, file = "SCB_Lower_Bike_beta2_95.csv")  #ns*nt
write.csv(Upper_Gamma, file = "SCB_Upper_Bike_gamma_95.csv")  #ns*nt
write.csv(Lower_Gamma, file = "SCB_Lower_Bike_gamma_95.csv")  #ns*nt
plot(1:24,gamma.hat, type = "l", xlim = c(1, 24), xlab = "Hour", ylab = "", las = 1)
lines(1:24, Upper_Gamma, col = "red", lty = 2)
lines(1:24, Lower_Gamma, col = "red", lty = 2)
abline(h=0, col = "grey")
S1 = 0
s1 = 0
for(i in 1:24){
for(j in 1:24){
if((Lower_B1[i, j]<=0)&(Upper_B1[i, j]>=0))
S1 = S1+1
else{
s1 = s1+1
}
}
}
S1
s1
S2 = 0
s2 = 0
for(i in 1:24){
for(j in 1:24){
if((Lower_B2[i, j]<=0)&(Upper_B2[i, j]>=0))
S2 = S2+1
else{
s2 = s2+1
}
}
}
S2
s2
plot(1:24,gamma.hat, type = "l", xlim = c(1, 24), ylim = c(-1.8, 1.8),xlab = "Hour", ylab = "", las = 1)
lines(1:24, Upper_Gamma, col = "red", lty = 2)
lines(1:24, Lower_Gamma, col = "red", lty = 2)
plot(1:24,gamma.hat, type = "l", xlim = c(1, 24), ylim = c(-2.0, 2.0),xlab = "Hour", ylab = "", las = 1)
lines(1:24, Upper_Gamma, col = "red", lty = 2)
plot(1:24,gamma.hat, type = "l", xlim = c(1, 24), ylim = c(-2.5, 2.5),xlab = "Hour", ylab = "", las = 1)
lines(1:24, Upper_Gamma, col = "red", lty = 2)
lines(1:24, Lower_Gamma, col = "red", lty = 2)
abline(h=0, col = "grey")
plot(1:24,gamma.hat, type = "l", xlim = c(1, 24), ylim = c(-2.5, 2.5),xlab = "Hour", ylab = "log(Y+1)",ylab = "", las = 1, cex.lab = 1.5, cex.axis = 1.5)
plot(1:24,gamma.hat, type = "l", xlim = c(1, 24), ylim = c(-2.5, 2.5),xlab = "Hour", ylab = "log(Y+1)", las = 1, cex.lab = 1.5, cex.axis = 1.5)
lines(1:24, Upper_Gamma, col = "red", lty = 2)
lines(1:24, Lower_Gamma, col = "red", lty = 2)
abline(h=0, col = "grey")
str(Y)
plot(1:24,gamma.hat, type = "l", xlim = c(1, 24), ylim = c(-2.5, 2.5),xlab = "Hour", ylab = expression(gamma), las = 1, cex.lab = 1.5, cex.axis = 1.5)
lines(1:24, Upper_Gamma, col = "red", lty = 2)
lines(1:24, Lower_Gamma, col = "red", lty = 2)
abline(h=0, col = "grey")
plot(Y[1,], xlab="Hour", ylab="log(Y+1)",type = "l",las = 1, cex.lab = 1.5, cex.axis = 1.5)
for(i in 2:181){
lines(Y[i,])
}
nonworking=which(Z==0)
working=which(Z==1)
nonworking
working
par(mar=c(5,6,4,1)+.1)
plot(1:24,gamma.hat, type = "l", xlim = c(1, 24), ylim = c(-2.5, 2.5),xlab = "Hour", ylab = expression(gamma), las = 1, cex.lab = 1.5, cex.axis = 1.5)
lines(1:24, Upper_Gamma, col = "red", lty = 2)
lines(1:24, Lower_Gamma, col = "red", lty = 2)
abline(h=0, col = "grey")
plot(1:24,gamma.hat, type = "l", xlim = c(1, 24), ylim = c(-2.5, 2.5),xlab = "Hour", ylab = expression(gamma), las = 1, cex.lab = 1.5, lwd=2,cex.axis = 1.5, font.lab=2, font.axis=2)
lines(1:24, Upper_Gamma, lwd=2, col = "red", lty = 2)
lines(1:24, Lower_Gamma, lwd=2, col = "red", lty = 2)
abline(h=0, col = "grey")
abline(h=0, lwd=2, col = "grey")
par(mar=c(5,6,4,1)+.1)
plot(1:24,gamma.hat, type = "l", xlim = c(1, 24), ylim = c(-2.5, 2.5),xlab = "Hour", ylab = expression(gamma), las = 1, cex.lab = 1.5, lwd=2,cex.axis = 1.5, font.lab=2, font.axis=2)
lines(1:24, Upper_Gamma, lwd=2, col = "red", lty = 2)
lines(1:24, Lower_Gamma, lwd=2, col = "red", lty = 2)
abline(h=0, lwd=2, col = "grey")
plot(1:24,gamma.hat, type = "l", xlim = c(1, 24), ylim = c(-2.5, 2.5),xlab = "Hour", ylab = expression(gamma), las = 1, cex.lab = 1.5, lwd=3,cex.axis = 1.5, font.lab=2, font.axis=2)
lines(1:24, Upper_Gamma, lwd=3, col = "red", lty = 2)
lines(1:24, Lower_Gamma, lwd=3, col = "red", lty = 2)
abline(h=0, lwd=3, col = "grey")
library(maps)
library(MASS) #mvnorm
Grid=list()
Grid[[1]]=seq(1/N[1],1.00,length.out = N[1])
Grid[[2]]=seq(1/N[2],1.00,length.out = N[2])
x_data.1=as.vector(replicate(N[2], Grid[[1]]))
x_data.2=as.vector(t(replicate(N[1], Grid[[2]])))
x_train=cbind(x_data.1, x_data.2)
Grid=list()
Grid[[1]]=seq(1/N[1],1.00,length.out = N[1])
Grid[[2]]=seq(1/N[2],1.00,length.out = N[2])
x_data.1=as.vector(replicate(N[2], Grid[[1]]))
x_data.2=as.vector(t(replicate(N[1], Grid[[2]])))
x_train=cbind(x_data.1, x_data.2)
d=2; N=c(3, 5); n=50
## Generate data
Grid=list()
Grid[[1]]=seq(1/N[1],1.00,length.out = N[1])
Grid[[2]]=seq(1/N[2],1.00,length.out = N[2])
x_data.1=as.vector(replicate(N[2], Grid[[1]]))
x_data.2=as.vector(t(replicate(N[1], Grid[[2]])))
x_train=cbind(x_data.1, x_data.2)
x_train
y_train.true=x_data.1^2+x_data.2
image(matrix(y_train.true, N[1], N[2]))
cov=array(NA, c(N[1]*N[2], N[1]*N[2], 2))
for(i in 1:(N[1]*N[2])){
for(j in 1:(N[1]*N[2])){
cov[i,j,1]=cos(2*pi*(x_data.1[i] - x_data.1[j]))
cov[i,j,2]=cos(2*pi*(x_data.2[i] - x_data.2[j]))
}
}
Data=array(NA, c(n, N[1], N[2]))
for(i in 1:n){
#Gaussian process and measurement error
error=mvrnorm(1, rep(0, N[1]*N[2]), (cov[,,1]+cov[,,2]))+rnorm(1, 0, 1)
Data[i,,]=matrix(error, N[1], N[2])+matrix(y_train.true, N[1], N[2])
}
str(Data)
y_train=apply(Data,c(2, 3),mean)
str(y_train)
image(y_train)
library(keras)
model <- keras_model_sequential()
model <- keras_model_sequential()
model %>%
layer_dense(units = 100,  kernel_regularizer = regularizer_l1(0.01), bias_regularizer = regularizer_l1(0.01), activation = "relu", input_shape = c(d),kernel_initializer = "normal", constraint_maxnorm(max_value = 1, axis = 0))
for(xx in  1:3){
model %>% layer_dense(units = 100,  kernel_regularizer = regularizer_l1(0.01), bias_regularizer = regularizer_l1(0.01), activation = "relu",kernel_initializer = "normal", constraint_maxnorm(max_value = 1, axis = 0))
}
model %>% layer_dense(units = 1)
model %>% compile(
loss = "mse",
optimizer = optimizer_adam(),
metrics = list("mean_squared_error")
)
history <- model %>% fit(
x_train, as.vector(y_train),
epochs = 50, batch_size = 16
)
y.reg=model %>% predict(x_train)
par(mfrow=c(1,2))
image(matrix(y.reg, N[1], N[2]))
image(matrix(y_train.true, N[1], N[2]))
d=2; N=c(3, 5); n=50
## Generate data
Grid=list()
Grid[[1]]=seq(1/N[1],1.00,length.out = N[1])
Grid[[2]]=seq(1/N[2],1.00,length.out = N[2])
x_data.1=as.vector(replicate(N[2], Grid[[1]]))
x_data.2=as.vector(t(replicate(N[1], Grid[[2]])))
x_train=cbind(x_data.1, x_data.2)
plot(x_train)
par(mfrow=c(1,1))
d=2; N=c(3, 5); n=50
Grid=list()
Grid[[1]]=seq(1/N[1],1.00,length.out = N[1])
Grid[[2]]=seq(1/N[2],1.00,length.out = N[2])
x_data.1=as.vector(replicate(N[2], Grid[[1]]))
x_data.2=as.vector(t(replicate(N[1], Grid[[2]])))
x_train=cbind(x_data.1, x_data.2)
par(mfrow=c(1,1))
d=2; N=c(3, 5); n=50
Grid=list()
Grid[[1]]=seq(1/N[1],1.00,length.out = N[1])
Grid[[2]]=seq(1/N[2],1.00,length.out = N[2])
x_data.1=as.vector(replicate(N[2], Grid[[1]]))
x_data.2=as.vector(t(replicate(N[1], Grid[[2]])))
x_train=cbind(x_data.1, x_data.2)
plot(x_train)
y_train.true=x_data.1^2+x_data.2
cov=array(NA, c(N[1]*N[2], N[1]*N[2], 2))
for(i in 1:(N[1]*N[2])){
for(j in 1:(N[1]*N[2])){
cov[i,j,1]=cos(2*pi*(x_data.1[i] - x_data.1[j]))
cov[i,j,2]=cos(2*pi*(x_data.2[i] - x_data.2[j]))
}
}
library(devtools)
devtools::install_github("FDASTATAUBURN/FDADNN")
library("FDAonDNN", lib.loc="/Library/Frameworks/R.framework/Versions/3.6/Resources/library")
remove.packages("FDAonDNN")
library(devtools)
devtools::install_github("FDASTATAUBURN/FDADNN")
library(FDAonDNN)
remove.packages("FDAonDNN")
library(MASS) #mvnorm
par(mfrow=c(1,1))
d=2
N=c(3, 5)
n=50
Grid=list()
Grid[[1]]=seq(1/N[1],1.00,length.out = N[1])
Grid[[2]]=seq(1/N[2],1.00,length.out = N[2])
x_data.1=as.vector(replicate(N[2], Grid[[1]]))
x_data.2=as.vector(t(replicate(N[1], Grid[[2]])))
x_train=cbind(x_data.1, x_data.2)
plot(x_train)
y_train.true=x_data.1^2+x_data.2
cov=array(NA, c(N[1]*N[2], N[1]*N[2], 2))
for(i in 1:(N[1]*N[2])){
for(j in 1:(N[1]*N[2])){
cov[i,j,1]=cos(2*pi*(x_data.1[i] - x_data.1[j]))
cov[i,j,2]=cos(2*pi*(x_data.2[i] - x_data.2[j]))
}
}
str(cov)
Data=array(NA, c(n, N[1], N[2]))
for(i in 1:n){
#Gaussian process and measurement error
error=mvrnorm(1, rep(0, N[1]*N[2]), (cov[,,1]+cov[,,2]))+rnorm(1, 0, 1)
Data[i,,]=matrix(error, N[1], N[2])+matrix(y_train.true, N[1], N[2])
}
y_train=apply(Data,c(2, 3),mean)
str(y_train)
image(y_train)
image(matrix(y_train.true, 3, 5))
par(mfrow=c(1,2))
image(matrix(y_train.true, 3, 5))
image(y_train)
library(keras)
model <- keras_model_sequential()
model %>%
layer_dense(units = 100,  kernel_regularizer = regularizer_l1(0.01), bias_regularizer = regularizer_l1(0.01), activation = "relu", input_shape = c(d),kernel_initializer = "normal", constraint_maxnorm(max_value = 1, axis = 0))
for(xx in  1:3){
model %>% layer_dense(units = 100,  kernel_regularizer = regularizer_l1(0.01), bias_regularizer = regularizer_l1(0.01), activation = "relu",kernel_initializer = "normal", constraint_maxnorm(max_value = 1, axis = 0))
}
model %>% layer_dense(units = 1)
model %>% compile(
loss = "mse",
optimizer = optimizer_adam(),
metrics = list("mean_squared_error")
)
history <- model %>% fit(
x_train, as.vector(y_train),
epochs = 50, batch_size = 16
)
y.reg=model %>% predict(x_train)
par(mfrow=c(1,2))
image(matrix(y.reg, N[1], N[2]))
image(matrix(y_train.true, N[1], N[2]))
library(devtools)
devtools::install_github("FDASTATAUBURN/FDADNN")
library(FDAonDNN)
?FDADNN
library("FDADNN", lib.loc="/Library/Frameworks/R.framework/Versions/3.6/Resources/library")
library("FDAonDNN", lib.loc="/Library/Frameworks/R.framework/Versions/3.6/Resources/library")
remove.packages("FDADNN")
detach("package:FDAonDNN", unload=TRUE)
devtools::install_github("FDASTATAUBURN/FDADNN")
library(FDADNN)
?FDADNN
remove.packages("FDADNN")
devtools::install_github("FDASTATAUBURN/FDADNN")
library(FDADNN)
?FDADNN
d=3; N=c(2, 3, 4); n=50
Grid=list()
Grid[[1]]=seq(1/N[1],1,length.out = N[1])
Grid[[2]]=seq(1/N[2],1,length.out = N[2])
Grid[[3]]=seq(1/N[3],1,length.out = N[3])
x1=rep(rep(Grid[[1]],N[2]*N[3]))
x2=rep(rep(Grid[[2]],each=N[1]),N[3])
x3=rep(Grid[[3]],each=N[1]*N[2])
x_train=cbind(x1,x2,x3)
y_train.true=exp(1/3*sin(2*pi*x1)+1/2*x2+sqrt(x3+0.1))
cov=array(NA, c(N[1]*N[2]*N[3], N[1]*N[2]*N[3], 3))
for(i in 1:(N[1]*N[2]*N[3])){
for(j in 1:(N[1]*N[2]*N[3])){
cov[i,j,1]=cos(2*pi*(x1[i] - x1[j]))
cov[i,j,2]=cos(2*pi*(x2[i] - x2[j]))
cov[i,j,3]=cos(2*pi*(x3[i] - x3[j]))
}
}
Data=list()
for(i in 1:n){
error=mvrnorm(1, rep(0, N[1]*N[2]*N[3]), (cov[,,1]+cov[,,2]+cov[,,3]))+rnorm(1, 0, 1)
Data[[i]]=array(error, c(N[1], N[2], N[3]))+array(y_train.true, c(N[1], N[2], N[3]))
}
f3=FDADNN(Data, d, Grid, N, n, 3, 100, 0.01, 100, 32, 5)
d=2; N=c(3, 5); n=50
## Generate data
Grid=list()
Grid[[1]]=seq(1/N[1],1.00,length.out = N[1])
Grid[[2]]=seq(1/N[2],1.00,length.out = N[2])
x_data.1=as.vector(replicate(N[2], Grid[[1]]))
x_data.2=as.vector(t(replicate(N[1], Grid[[2]])))
x_train=cbind(x_data.1, x_data.2)
## True function
y_train.true=(-8)*1/(1+exp(cot(x_data.1^2)*cos(2*pi*x_data.2)))
## Covariance structure
cov=array(NA, c(N[1]*N[2], N[1]*N[2], 2))
for(i in 1:(N[1]*N[2])){
for(j in 1:(N[1]*N[2])){
cov[i,j,1]=cos(2*pi*(x_data.1[i] - x_data.1[j]))
cov[i,j,2]=cos(2*pi*(x_data.2[i] - x_data.2[j]))
}
}
Data=list()
for(i in 1:n){
error=mvrnorm(1, rep(0, N[1]*N[2]), (cov[,,1]+cov[,,2]))+rnorm(1, 0, 1)
Data[[i]]=matrix(error, N[1], N[2])+matrix(y_train.true, N[1], N[2])
}
f2=FDADNN(Data, d, Grid, N, n, 3, 100, 0.01, 100, 32, 5)
f2
f3
library(pracma)
library(MASS)
d=3; N=c(2, 3, 4); n=50
Grid=list()
Grid[[1]]=seq(1/N[1],1,length.out = N[1])
Grid[[2]]=seq(1/N[2],1,length.out = N[2])
Grid[[3]]=seq(1/N[3],1,length.out = N[3])
x1=rep(rep(Grid[[1]],N[2]*N[3]))
x2=rep(rep(Grid[[2]],each=N[1]),N[3])
x3=rep(Grid[[3]],each=N[1]*N[2])
x_train=cbind(x1,x2,x3)
y_train.true=exp(1/3*sin(2*pi*x1)+1/2*x2+sqrt(x3+0.1))
cov=array(NA, c(N[1]*N[2]*N[3], N[1]*N[2]*N[3], 3))
for(i in 1:(N[1]*N[2]*N[3])){
for(j in 1:(N[1]*N[2]*N[3])){
cov[i,j,1]=cos(2*pi*(x1[i] - x1[j]))
cov[i,j,2]=cos(2*pi*(x2[i] - x2[j]))
cov[i,j,3]=cos(2*pi*(x3[i] - x3[j]))
}
}
Data=list()
for(i in 1:n){
error=mvrnorm(1, rep(0, N[1]*N[2]*N[3]), (cov[,,1]+cov[,,2]+cov[,,3]))+rnorm(1, 0, 1)
Data[[i]]=array(error, c(N[1], N[2], N[3]))+array(y_train.true, c(N[1], N[2], N[3]))
}
f3=FDADNN(Data, d, Grid, N, n, 3, 100, 0.01, 100, 32, 5)
d=2; N=c(3, 5); n=50
## Generate data
Grid=list()
Grid[[1]]=seq(1/N[1],1.00,length.out = N[1])
Grid[[2]]=seq(1/N[2],1.00,length.out = N[2])
x_data.1=as.vector(replicate(N[2], Grid[[1]]))
x_data.2=as.vector(t(replicate(N[1], Grid[[2]])))
x_train=cbind(x_data.1, x_data.2)
## True function
y_train.true=(-8)*1/(1+exp(cot(x_data.1^2)*cos(2*pi*x_data.2)))
## Covariance structure
cov=array(NA, c(N[1]*N[2], N[1]*N[2], 2))
for(i in 1:(N[1]*N[2])){
for(j in 1:(N[1]*N[2])){
cov[i,j,1]=cos(2*pi*(x_data.1[i] - x_data.1[j]))
cov[i,j,2]=cos(2*pi*(x_data.2[i] - x_data.2[j]))
}
}
Data=list()
for(i in 1:n){
error=mvrnorm(1, rep(0, N[1]*N[2]), (cov[,,1]+cov[,,2]))+rnorm(1, 0, 1)
Data[[i]]=matrix(error, N[1], N[2])+matrix(y_train.true, N[1], N[2])
}
f2=FDADNN(Data, d, Grid, N, n, 3, 100, 0.01, 100, 32, 5)
f2
f3
f3
f3$plot.dnn
f3$estimation
f2$plot.dnn
x_train
plot3D::scatter3D(x_train[,1],x_train[,2],x_train[,3],colvar = y.reg, pch=16, phi=0, theta=30, colkey=FALSE, xlab="x1", ylab="x2", zlab="x3")
plot3D::scatter3D(x1[,1],x2[,2],x3[,3],colvar = y.reg, pch=16, phi=0, theta=30, colkey=FALSE, xlab="x1", ylab="x2", zlab="x3")
plot3D::scatter3D(x1,x2,x3,colvar = y.reg, pch=16, phi=0, theta=30, colkey=FALSE, xlab="x1", ylab="x2", zlab="x3")
plot3D::scatter3D(x1,x2,x3,colvar = y_train.true, pch=16, phi=0, theta=30, colkey=FALSE, xlab="x1", ylab="x2", zlab="x3")
x1
x2
x3
y_train.true=exp(1/3*sin(2*pi*x1)+1/2*x2+sqrt(x3+0.1))
plot3D::scatter3D(x1,x2,x3,colvar = y_train.true, pch=16, phi=0, theta=30, colkey=FALSE, xlab="x1", ylab="x2", zlab="x3")
p=plot3D::scatter3D(x1,x2,x3,colvar = y_train.true, pch=16, phi=0, theta=30, colkey=FALSE, xlab="x1", ylab="x2", zlab="x3")
p
print(p)
y_train.true
library(plot3D)
?scatter3D
f2
f3
f3$plot.dnn
trans3d(f3$plot.dnn)
as.vector(f3$estimation)
remove.packages("FDAonDNN")
remove.packages("FDADNN")
devtools::install_github("FDASTATAUBURN/FDADNN")
library(FDADNN)
?FDADNN
library(FDADNN)
?FDADNN
setwd("~/Desktop/AU_PHD/20-21_Spring/FDADNN_3rd_version_Nogithub")
devtools::document()
setwd("~/Desktop/AU_PHD/20-21_Spring/FDADNN_3rd_version_Nogithub/R")
devtools::load_all()
devtools::install()
library(FDADNN)
?FDADNN
